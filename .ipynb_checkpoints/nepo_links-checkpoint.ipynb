{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3ad038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import wikipediaapi as wiki\n",
    "import spotipy\n",
    "import billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cefc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent and Relative strings to search for in wikipedia infobox\n",
    "parent_pattern = re.compile('Parent|Relative')\n",
    "\n",
    "# url base\n",
    "wiki_url_base = \"https://en.wikipedia.org\" # wikipedia\n",
    "imdb_base_url = \"https://www.imdb.com\"\n",
    "\n",
    "# wikipedia language setting\n",
    "wiki_wiki = wiki.Wikipedia('en')\n",
    "\n",
    "# imdb links\n",
    "# Most Popular TV Shows as determined by IMDb Users\n",
    "url_pop_tv = \"https://www.imdb.com/chart/tvmeter?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=DK1W37ZH61RXZP184X95&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=toptv&ref_=chttvtp_ql_5\"\n",
    "\n",
    "# Most Popular Movies as determined by IMDb Users\n",
    "url_pop_mov = \"https://www.imdb.com/chart/moviemeter?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=408FM1WEANBKDGP51PET&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_ql_2\"\n",
    "\n",
    "# Top Box Office (US) - updated weekly\n",
    "url_box_office = \"https://www.imdb.com/chart/boxoffice?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=KK2KJN75YN0PGF8Q79QK&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=moviemeter&ref_=chtmvm_ql_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4316cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name of person, outputs parent links or false if none\n",
    "def wiki_scrape(name):\n",
    "    subject = name.replace(\" \", \"_\")\n",
    "    url = wiki_url_base + \"/wiki/\" + subject\n",
    "\n",
    "    # check if wiki page exists\n",
    "    wiki_page = wiki_wiki.page(subject)\n",
    "    does_page_exist = wiki_page.exists()\n",
    "\n",
    "    if does_page_exist is False :\n",
    "        return False # no wiki page -> not famous enough, not a nepo baby\n",
    "    \n",
    "    elif does_page_exist is True : \n",
    "        data = requests.get(url).text\n",
    "        soup = BeautifulSoup(data,'html.parser') # full page\n",
    "        \n",
    "        # check if infobox exists\n",
    "        infobox = soup.find(\"table\",{\"class\":\"infobox biography vcard\"}) # infobox\n",
    "        \n",
    "        if infobox is None :\n",
    "            return False # no infobox on wiki page -> not a nepo baby\n",
    "        else :\n",
    "            does_parent_field_exist = bool(re.search(\"Parent|Relative\", infobox.text)) # see if Parent or Relative field is listed in infobox\n",
    "        \n",
    "            if does_parent_field_exist is False :\n",
    "                return False # parent field not listed in infobox -> not a nepo baby\n",
    "            elif does_parent_field_exist is True :\n",
    "                parent_field = soup.find('th', string=parent_pattern).parent\n",
    "                parent_a_tags = parent_field.find_all('a')\n",
    "                if len(parent_a_tags) == 0 :\n",
    "                    return False # parents listed in infobox but not linked -> not a nepo baby\n",
    "                else : # nepo baby!\n",
    "                    parent_wiki_list = []\n",
    "                    for link in parent_field.find_all('a'):\n",
    "                        parent_wiki = link.get('href')\n",
    "                        parent_wiki_link = wiki_url_base + parent_wiki\n",
    "                        parent_wiki_list.append(parent_wiki_link)\n",
    "                        \n",
    "                        parent_wiki_list[:] = [x for x in parent_wiki_list if \"cite_note\" not in x] # cited entries are in <a href> tags so remove those links here\n",
    "    \n",
    "                return parent_wiki_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d10ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_nepo(df, group_col):\n",
    "    df = df[[group_col, 'nepos']]\n",
    "    df = df[df.nepos != False].groupby(group_col).count() / df.groupby(group_col).count() * 100\n",
    "    df = df.rename(columns={'nepos': 'pct_nepo'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_list_links(url):\n",
    "    page_data = requests.get(url).text\n",
    "    soup = BeautifulSoup(page_data,'html.parser')\n",
    "    \n",
    "    media_table = soup.find(\"table\", {\"class\":\"chart full-width\"}) \n",
    "    \n",
    "    all_links = []\n",
    "    \n",
    "    # media is linked twice in each row -- specify td (column) = 2 to avoid dupes\n",
    "    for tag in media_table.select(\"a\"):\n",
    "        all_links.append(imdb_base_url + tag[\"href\"])\n",
    "\n",
    "    # media is linked twice in each row \n",
    "    # tried select(\"td:nth-of-type(2) a\") in the for loop above but that didn't work for all imdb links\n",
    "    df = pd.DataFrame(columns=[\"link\"], data = all_links).drop_duplicates()\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62eda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_cast(url):\n",
    "    page_data =  requests.get(url).text\n",
    "    soup = BeautifulSoup(page_data,'html.parser')\n",
    "    \n",
    "    title = soup.find(\"h1\")\n",
    "    title = title.text\n",
    "    \n",
    "    # grab top cast section of imdb page\n",
    "    top_cast = soup.find_all(\"a\", {\"class\": \"sc-36c36dd0-1 QSQgP\"})\n",
    "    \n",
    "    cast_list = []\n",
    "    \n",
    "    # get cast names\n",
    "    for a in top_cast:\n",
    "        cast_list.append(str(a.string))\n",
    "        \n",
    "    return[title, cast_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_whole_shebang(url):\n",
    "    df = get_imdb_list_links(url)\n",
    "    df['imdb_info'] = df.apply(lambda row : top_cast(row['link']), axis=1)\n",
    "    df = pd.DataFrame(df[\"imdb_info\"].to_list(), columns=['title', 'cast'])\n",
    "    df = df.explode('cast').reset_index(drop=True)\n",
    "    df.loc[:,\"nepos\"] = df.apply(lambda row : wiki_scrape(row['cast']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_tv_df = imdb_whole_shebang(url_pop_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_tv_pct = pct_nepo(pop_tv_df, 'title')\n",
    "pop_tv_df_1 = pop_tv_df.merge(pop_tv_pct, on=['title'], how='left')\n",
    "pop_tv_df_1.to_csv(\"pop_tv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbe6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mov_df = imdb_whole_shebang(url_pop_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb85e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office_df = imdb_whole_shebang(url_box_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250687a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = billboard.ChartData('hot-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_artists = billboard.ChartData(\"top-artists\", year='2021', fetch=True, timeout=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f1488c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_for_billboard_charts = ['2016', '2017', '2018', '2019', '2020', '2021']\n",
    "categories_for_billboard_charts = ['top-artists', 'top-rock-artists', 'top-r&b-artists', \n",
    "                                   'top-dance-electronic-artists', 'top-latin-artists']\n",
    "\n",
    "artists = []\n",
    "\n",
    "for yr in years_for_billboard_charts :\n",
    "    for category in categories_for_billboard_charts :\n",
    "        for i in billboard.ChartData(category, year=yr):\n",
    "            artists.append({'year': yr,\n",
    "                            'chart': category,\n",
    "                            'artist': i.artist})\n",
    "            \n",
    "artist_df = pd.DataFrame(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22a6b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df[\"nepos\"] = artist_df.apply(lambda row : wiki_scrape(row['Artist']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41792713",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_pct = pct_nepo(artist_df, 'Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "128e0d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_nepo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chart</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top-artists</th>\n",
       "      <td>12.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-dance-electronic-artists</th>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-latin-artists</th>\n",
       "      <td>6.688963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-r&amp;b-artists</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-rock-artists</th>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pct_nepo\n",
       "Chart                                  \n",
       "top-artists                   12.166667\n",
       "top-dance-electronic-artists   7.333333\n",
       "top-latin-artists              6.688963\n",
       "top-r&b-artists                8.000000\n",
       "top-rock-artists               5.666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa9f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
