{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f48249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import wikipediaapi as wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0fd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# met gala attendees\n",
    "df = pd.read_csv(r'/Users/jessicacarr/Documents/J/nepos/nepos_met gala.csv')\n",
    "\n",
    "# Parent and Relative strings to search for in wikipedia infobox\n",
    "parent_pattern = re.compile('Parent|Relative')\n",
    "\n",
    "# wikipedia url base\n",
    "url_base = \"https://en.wikipedia.org\"\n",
    "\n",
    "# wikipedia language setting\n",
    "wiki_wiki = wiki.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3833cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name of person, outputs parent links or false if none\n",
    "def wiki_scrape(name):\n",
    "    subject = name.replace(\" \", \"_\")\n",
    "    url = url_base + \"/wiki/\" + subject\n",
    "\n",
    "    # check if wiki page exists\n",
    "    wiki_page = wiki_wiki.page(subject)\n",
    "    does_page_exist = wiki_page.exists()\n",
    "\n",
    "    if does_page_exist is False :\n",
    "        return [name, False] # no wiki page -> not famous enough, not a nepo baby\n",
    "    \n",
    "    elif does_page_exist is True : \n",
    "        data = requests.get(url).text\n",
    "        soup = BeautifulSoup(data,'html.parser') # full page\n",
    "        \n",
    "        # check if infobox exists\n",
    "        infobox = soup.find(\"table\",{\"class\":\"infobox biography vcard\"}) # infobox\n",
    "        \n",
    "        if infobox is None :\n",
    "            return [name, False] # no infobox on wiki page -> not a nepo baby\n",
    "        else :\n",
    "            does_parent_field_exist = bool(re.search(\"Parent|Relative\", infobox.text)) # see if Parent or Relative field is listed in infobox\n",
    "        \n",
    "            if does_parent_field_exist is False :\n",
    "                return [name, False]\n",
    "            elif does_parent_field_exist is True :\n",
    "                parent_field = soup.find('th', string=parent_pattern).parent\n",
    "                parent_a_tags = parent_field.find_all('a')\n",
    "                if len(parent_a_tags) == 0 :\n",
    "                    return [name, False] # parents listed in infobox but not linked -> not a nepo baby\n",
    "                else :\n",
    "                    parent_wiki_list = []\n",
    "                    for link in parent_field.find_all('a'):\n",
    "                        parent_wiki = link.get('href')\n",
    "                        parent_wiki_link = url_base + parent_wiki\n",
    "                        parent_wiki_list.append(parent_wiki_link)\n",
    "                        \n",
    "                        parent_wiki_list[:] = [x for x in parent_wiki_list if \"cite_note\" not in x] # cited entries are in <a href> tags so remove those links here\n",
    "    \n",
    "                return [name, parent_wiki_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba48124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to Top 100 Popular Shows\n",
    "url_top_tv = \"https://www.imdb.com/chart/tvmeter?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=DK1W37ZH61RXZP184X95&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=toptv&ref_=chttvtp_ql_5\"\n",
    "imdb_base_url = \"https://www.imdb.com\"\n",
    "\n",
    "# html parser\n",
    "data_top_tv = requests.get(url_top_tv).text\n",
    "soup_top_tv = BeautifulSoup(data_top_tv,'html.parser')\n",
    "\n",
    "top_tv_table = soup_top_tv.find(\"table\", {\"class\":\"chart full-width\"})\n",
    "top_tv_links = []\n",
    "\n",
    "for link in top_tv_table.find_all('a'):\n",
    "    tv_link = link.get('href')\n",
    "    tv_link = imdb_base_url + tv_link\n",
    "    top_tv_links.append(tv_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa06f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_imdb = top_tv_links[98] # tester for one show\n",
    "\n",
    "# get specific show imdb page\n",
    "data_imdb = requests.get(url_imdb).text\n",
    "soup_imdb = BeautifulSoup(data_imdb,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18740a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab top cast section of imdb page\n",
    "top_cast = soup_imdb.find_all(\"a\", {\"class\": \"sc-36c36dd0-1 QSQgP\"})\n",
    "\n",
    "# initialise list\n",
    "cast_names = []\n",
    "\n",
    "# get cast names\n",
    "for a in top_cast:\n",
    "    cast_names.append(a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e133ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Úrsula Corberó', False],\n",
       " ['Álvaro Morte', False],\n",
       " ['Itziar Ituño', False],\n",
       " ['Pedro Alonso', False],\n",
       " ['Miguel Herrán', False],\n",
       " ['Jaime Lorente', False],\n",
       " ['Esther Acebo', False],\n",
       " ['Darko Peric', False],\n",
       " ['Enrique Arce', False],\n",
       " ['Alba Flores', ['https://en.wikipedia.org/wiki/Antonio_Flores']],\n",
       " ['Fernando Soto', False],\n",
       " ['Mario de la Rosa', False],\n",
       " ['Hovik Keuchkerian', False],\n",
       " ['Rodrigo de la Serna', False],\n",
       " ['Najwa Nimri', False],\n",
       " ['Luka Peros', False],\n",
       " ['Fernando Cayo', False],\n",
       " ['Rocco Narva', False]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the nepo babies\n",
    "list(map(wiki_scrape, cast_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2ade3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alba Flores', ['https://en.wikipedia.org/wiki/Antonio_Flores']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ISSUES TO TROUBLESHOOT\n",
    "\n",
    "# 1: not returning all links -- only parent ones in this case:\n",
    "wiki_scrape(\"Alba Flores\")\n",
    "# may be because there is a parent listed with no link so then skips the relatives\n",
    "\n",
    "# 2: top_tv_links has duplicate links (len = 200 rather than 100) because there is a link in titleColumn and posterColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a89563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply wiki_scrape function\n",
    "#df[\"nepo\"] = df.apply(lambda row : wiki_scrape(row['attendee']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
