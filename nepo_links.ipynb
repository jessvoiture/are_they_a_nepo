{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ad038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import wikipediaapi as wiki\n",
    "import spotipy\n",
    "import billboard\n",
    "from datetime import datetime\n",
    "import imdb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cefc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent and Relative strings to search for in wikipedia infobox\n",
    "parent_pattern = re.compile('Parent|Relative')\n",
    "\n",
    "# url base\n",
    "wiki_url_base = \"https://en.wikipedia.org\" # wikipedia\n",
    "imdb_base_url = \"https://www.imdb.com\"\n",
    "imdb_search_base_url = 'https://www.imdb.com/title/tt'\n",
    "\n",
    "# wikipedia language setting\n",
    "wiki_wiki = wiki.Wikipedia('en')\n",
    "\n",
    "# imdb links\n",
    "# Most Popular TV Shows as determined by IMDb Users\n",
    "url_pop_tv = \"https://www.imdb.com/chart/tvmeter?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=DK1W37ZH61RXZP184X95&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=toptv&ref_=chttvtp_ql_5\"\n",
    "\n",
    "# Most Popular Movies as determined by IMDb Users\n",
    "url_pop_mov = \"https://www.imdb.com/chart/moviemeter?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=408FM1WEANBKDGP51PET&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_ql_2\"\n",
    "\n",
    "# Top Box Office (US) - updated weekly\n",
    "url_box_office = \"https://www.imdb.com/chart/boxoffice?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=470df400-70d9-4f35-bb05-8646a1195842&pf_rd_r=KK2KJN75YN0PGF8Q79QK&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=moviemeter&ref_=chtmvm_ql_1\"\n",
    "\n",
    "ia = imdb.Cinemagoer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name of person, outputs parent links or false if none\n",
    "def wiki_scrape(name):\n",
    "    subject = name.replace(\" \", \"_\")\n",
    "    url = wiki_url_base + \"/wiki/\" + subject\n",
    "\n",
    "    # check if wiki page exists\n",
    "    wiki_page = wiki_wiki.page(subject)\n",
    "    does_page_exist = wiki_page.exists()\n",
    "\n",
    "    if does_page_exist is False :\n",
    "        return False # no wiki page -> not famous enough, not a nepo baby\n",
    "    \n",
    "    elif does_page_exist is True : \n",
    "        data = requests.get(url).text\n",
    "        soup = BeautifulSoup(data,'html.parser') # full page\n",
    "        \n",
    "        # check if infobox exists\n",
    "        infobox = soup.find(\"table\",{\"class\":\"infobox biography vcard\"}) # infobox\n",
    "        \n",
    "        if infobox is None :\n",
    "            return False # no infobox on wiki page -> not a nepo baby\n",
    "        else :\n",
    "            does_parent_field_exist = bool(re.search(\"Parent|Relative\", infobox.text)) # see if Parent or Relative field is listed in infobox\n",
    "        \n",
    "            if does_parent_field_exist is False :\n",
    "                return False # parent field not listed in infobox -> not a nepo baby\n",
    "            elif does_parent_field_exist is True :\n",
    "                parent_field = soup.find('th', string=parent_pattern).parent\n",
    "                parent_a_tags = parent_field.find_all('a')\n",
    "                if len(parent_a_tags) == 0 :\n",
    "                    return False # parents listed in infobox but not linked -> not a nepo baby\n",
    "                else : # nepo baby!\n",
    "                    parent_wiki_list = []\n",
    "                    for link in parent_field.find_all('a'):\n",
    "                        parent_wiki = link.get('href')\n",
    "                        parent_wiki_link = wiki_url_base + parent_wiki\n",
    "                        parent_wiki_list.append(parent_wiki_link)\n",
    "                        \n",
    "                        parent_wiki_list[:] = [x for x in parent_wiki_list if \"cite_note\" not in x] # cited entries are in <a href> tags so remove those links here\n",
    "    \n",
    "                return parent_wiki_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e00db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_nepo(df, group_col):\n",
    "    df = df[[group_col, 'nepos']]\n",
    "    df = df[df.nepos != False].groupby(group_col).count() / df.groupby(group_col).count() * 100\n",
    "    df = df.rename(columns={'nepos': 'pct_nepo'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_list_links(url):\n",
    "    page_data = requests.get(url).text\n",
    "    soup = BeautifulSoup(page_data,'html.parser')\n",
    "    \n",
    "    media_table = soup.find(\"table\", {\"class\":\"chart full-width\"}) \n",
    "    \n",
    "    all_links = []\n",
    "    \n",
    "    # media is linked twice in each row -- specify td (column) = 2 to avoid dupes\n",
    "    for tag in media_table.select(\"a\"):\n",
    "        all_links.append(imdb_base_url + tag[\"href\"])\n",
    "\n",
    "    # media is linked twice in each row \n",
    "    # tried select(\"td:nth-of-type(2) a\") in the for loop above but that didn't work for all imdb links\n",
    "    df = pd.DataFrame(columns=[\"link\"], data = all_links).drop_duplicates()\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62eda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_specs(url):\n",
    "    page_data =  requests.get(url).text\n",
    "    soup = BeautifulSoup(page_data,'html.parser')\n",
    "    \n",
    "    # TITLE\n",
    "    title = soup.find(\"h1\")\n",
    "    title = title.text\n",
    "    \n",
    "    # CAST\n",
    "    # grab top cast section of imdb page\n",
    "    top_cast = soup.find_all(\"a\", {\"class\": \"sc-36c36dd0-1 QSQgP\"})\n",
    "    \n",
    "    cast_list = []\n",
    "    \n",
    "    # get cast names\n",
    "    for a in top_cast:\n",
    "        cast_list.append(str(a.string))\n",
    "        \n",
    "    # IMDB RATING\n",
    "    rating_tag = soup.find(\"span\", {\"class\": \"sc-7ab21ed2-1 jGRxWM\"})\n",
    "    if rating_tag is None :\n",
    "        rating = np.nan # some shows are in the popular list but haven't actually been released yet so no rating\n",
    "    else :\n",
    "        rating = rating_tag.string\n",
    "        \n",
    "    return[title, cast_list, rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_whole_shebang(url):\n",
    "    df = get_imdb_list_links(url)\n",
    "    df['imdb_info'] = df.apply(lambda row : title_specs(row['link']), axis=1)\n",
    "    df = pd.DataFrame(df[\"imdb_info\"].to_list(), columns=['title', 'cast', 'imdb_rating'])\n",
    "    df = df.explode('cast').reset_index(drop=True)\n",
    "    df.loc[:,\"nepos\"] = df.apply(lambda row : wiki_scrape(row['cast']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_tv_df = imdb_whole_shebang(url_pop_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2707960",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_tv_pct = pct_nepo(pop_tv_df, 'title')\n",
    "pop_tv_df_1 = pop_tv_df.merge(pop_tv_pct, on=['title'], how='left')\n",
    "pop_tv_df_1.to_csv(\"pop_tv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd736101",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mov_df = imdb_whole_shebang(url_pop_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb85e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office_df = imdb_whole_shebang(url_box_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charts start in 2016 and go up to most recent full year\n",
    "years_for_billboard_charts = list(range(2016, current_year-1))\n",
    "categories_for_billboard_charts = ['top-artists', 'top-rock-artists', 'top-r&b-artists', \n",
    "                                   'top-dance-electronic-artists', 'top-latin-artists']\n",
    "\n",
    "artists = []\n",
    "\n",
    "for yr in years_for_billboard_charts :\n",
    "    for category in categories_for_billboard_charts :\n",
    "        for i in billboard.ChartData(category, year=yr):\n",
    "            artists.append({'year': yr,\n",
    "                            'chart': category,\n",
    "                            'artist': i.artist})\n",
    "            \n",
    "artist_df = pd.DataFrame(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67eb28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df[\"nepos\"] = artist_df.apply(lambda row : wiki_scrape(row['artist']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_pct = pct_nepo(artist_df, 'Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_input = input(\"name: \")\n",
    "person_cnxn = wiki_scrape(person_input)\n",
    "\n",
    "if person_cnxn is False :\n",
    "    print(f\"{person_input} is not a nepo baby\")\n",
    "else :\n",
    "    print(f'{person_input} is a nepo baby. Here are the connection links: {person_cnxn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a473c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = input(\"movie or tv show: \")\n",
    "movie_choices = ia.search_movie(movie_input)\n",
    "\n",
    "movie_choices_list = []\n",
    "\n",
    "# only showing 5 possible options\n",
    "for i in range(5) :\n",
    "    \n",
    "    index = [1, 2, 3, 4, 5]\n",
    "    rank = index[i]\n",
    "    \n",
    "    movie_title = movie_choices[i]['title']\n",
    "    movie_id = movie_choices[i].movieID\n",
    "    \n",
    "    movie = ia.get_movie(movie_id)\n",
    "    \n",
    "    short_cast_list = []\n",
    "    try :\n",
    "        cast = movie['cast']\n",
    "        for i in range(3):\n",
    "            short_cast_list.append(cast[i]['name'])\n",
    "    \n",
    "        formatted_cast_list = f\"starring {short_cast_list[0]}, {short_cast_list[1]}, and {short_cast_list[2]}\"\n",
    "    except KeyError:\n",
    "        formatted_cast_list = \"\"\n",
    "    except IndexError:\n",
    "        formatted_cast_list = \"\"\n",
    "        \n",
    "    try :\n",
    "        year = movie['year']\n",
    "        year = f\" ({year})\"\n",
    "    except KeyError:\n",
    "        year = \"\"\n",
    "    print(f\"{rank}: {movie_title}{year} {formatted_cast_list}\")\n",
    "\n",
    "movie_choice_input = input(f'people are not very creative with titles so there are a few titles - which number is the correct one?: ')\n",
    "\n",
    "movie_id = movie_choices[int(movie_choice_input)-1].movieID\n",
    "movie_url = imdb_search_base_url + movie_id\n",
    "\n",
    "movie_full_cast = title_specs(movie_url)\n",
    "\n",
    "df = pd.DataFrame([movie_full_cast], columns=['title', 'cast', 'imdb_rating'])\n",
    "df = df.explode('cast').reset_index(drop=True)\n",
    "df.loc[:,\"nepos\"] = df.apply(lambda row : wiki_scrape(row['cast']), axis=1)\n",
    "title_pct_nepo = pct_nepo(df, 'title')\n",
    "pct_nepo_str = title_pct_nepo['pct_nepo'][0]\n",
    "\n",
    "nepo_rows = df[df['nepos'] != False]\n",
    "\n",
    "print(f'{movie_input} is {pct_nepo_str}% full of nepotism babies. The following people are the culprits: {nepo_rows}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f85be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepo_rows = df[df['nepos'] != False]\n",
    "nepo_rows.loc[0, \"cast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_pct_nepo['pct_nepo'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
